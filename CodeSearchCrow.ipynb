{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPFsI74mmlmj9jpnvjHkX7I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shun0212/CodeSearch-Crow/blob/main/CodeCrow_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers\n",
        "!pip install flash-attn lizard faiss-cpu"
      ],
      "metadata": {
        "id": "rDIz1f3SUV7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bITKgPsCT_yd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import json\n",
        "import lizard\n",
        "import faiss\n",
        "import torch\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# ===========================================\n",
        "# Settings\n",
        "# ===========================================\n",
        "GITHUB_REPO_URL = \"https://github.com/google-research/bert.git\"  # ğŸ”§ Change to any GitHub repo you want\n",
        "MODEL_NAME = \"Shuu12121/CodeSearch-ModernBERT-Crow-Plus\"\n",
        "MIN_FUNCTION_LENGTH = 3  # Only include functions/cells with 3+ lines\n",
        "SAVE_DIR = \"./cloned_repos\"\n",
        "\n",
        "# ãƒ•ã‚¡ã‚¤ãƒ«åå®šç¾©\n",
        "FUNCTIONS_FILE = \"functions.json\"\n",
        "INDEX_FILE = \"faiss_index.bin\"\n",
        "\n",
        "\n",
        "# ===========================================\n",
        "# Helper Functions\n",
        "# ===========================================\n",
        "\n",
        "def clone_repository(repo_url, clone_dir):\n",
        "    \"\"\"\n",
        "    Clone the GitHub repository if not already cloned.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(clone_dir):\n",
        "        subprocess.run([\"git\", \"clone\", repo_url, clone_dir], check=True)\n",
        "        print(f\"âœ… Repository cloned to {clone_dir}\")\n",
        "    else:\n",
        "        print(f\"â„¹ï¸ Repository already exists at {clone_dir}. Skipping clone.\")\n",
        "\n",
        "\n",
        "def extract_functions(repo_path):\n",
        "    \"\"\"\n",
        "    Extract functions from .py and .ipynb files.\n",
        "    Uses lizard's long_name to include class names if available.\n",
        "    \"\"\"\n",
        "    functions = []\n",
        "    print(\"ğŸ“¥ Extracting functions...\")\n",
        "    for root, _, files in os.walk(repo_path):\n",
        "        # .gitãªã©ã®éš ã—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚„ä¸è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚¹ã‚­ãƒƒãƒ— (å‰å›ã®ä¿®æ­£ã§è¿½åŠ ã—ãŸè¦ç´ )\n",
        "        if \".git\" in root or \".ipynb_checkpoints\" in root:\n",
        "             continue\n",
        "\n",
        "        files.sort()  # Sort files for stable order\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            try:\n",
        "                if file.endswith(\".py\"):\n",
        "                    analysis = lizard.analyze_file(file_path)\n",
        "                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "                        lines = f.readlines()\n",
        "                    for func in analysis.function_list:\n",
        "                        if hasattr(func, 'start_line') and hasattr(func, 'end_line'):\n",
        "                            start, end = max(func.start_line - 1, 0), func.end_line\n",
        "                            code = \"\".join(lines[start:end]) # ã‚³ãƒ¼ãƒ‰ã‚’æ–‡å­—åˆ—ã¨ã—ã¦çµåˆ\n",
        "                            if len(code.strip().splitlines()) >= MIN_FUNCTION_LENGTH:\n",
        "                                functions.append({\n",
        "                                    \"file_path\": file_path,\n",
        "                                    \"function_name\": func.long_name,  # Use long_name (with class if exists)\n",
        "                                    \"code\": code\n",
        "                                })\n",
        "                elif file.endswith(\".ipynb\"):\n",
        "                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "                        data = json.load(f)\n",
        "                    for idx, cell in enumerate(data.get(\"cells\", [])):\n",
        "                        if cell.get(\"cell_type\") == \"code\":\n",
        "                            code = \"\".join(cell.get(\"source\", []))\n",
        "                            if len(code.strip().splitlines()) >= MIN_FUNCTION_LENGTH:\n",
        "                                functions.append({\n",
        "                                    \"file_path\": file_path,\n",
        "                                    \"function_name\": f\"cell_{idx}\",\n",
        "                                    \"code\": code\n",
        "                                })\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸ Warning: Could not process {file_path}: {e}\")\n",
        "\n",
        "    print(f\"âœ… Extracted {len(functions)} functions.\")\n",
        "    return functions\n",
        "\n",
        "\n",
        "def embed_codes(codes, model):\n",
        "    \"\"\"\n",
        "    Embed code snippets into dense vectors.\n",
        "    \"\"\"\n",
        "    print(\"\\nğŸ“ˆ Encoding function codes...\")\n",
        "    return model.encode(codes, batch_size=32, show_progress_bar=True, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def build_faiss_index(embeddings):\n",
        "    \"\"\"\n",
        "    Build a FAISS index from embeddings.\n",
        "    \"\"\"\n",
        "    print(\"\\nğŸ—ï¸ Building FAISS index...\")\n",
        "    dim = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatL2(dim)\n",
        "    index.add(embeddings)\n",
        "    return index\n",
        "\n",
        "\n",
        "def load_or_build_data_and_index(clone_path, model):\n",
        "    \"\"\"\n",
        "    Load existing functions data and FAISS index, or build them if not found.\n",
        "    \"\"\"\n",
        "    functions_path = os.path.join(clone_path, FUNCTIONS_FILE)\n",
        "    index_path = os.path.join(clone_path, INDEX_FILE)\n",
        "\n",
        "    # Check if both data and index files exist\n",
        "    if os.path.exists(functions_path) and os.path.exists(index_path):\n",
        "        print(f\"\\nğŸ”„ Loading existing data and index from {clone_path}...\")\n",
        "        try:\n",
        "            # Load functions data\n",
        "            with open(functions_path, 'r', encoding='utf-8') as f:\n",
        "                functions = json.load(f)\n",
        "            # Load FAISS index\n",
        "            index = faiss.read_index(index_path)\n",
        "            print(\"âœ… Successfully loaded existing data and index.\")\n",
        "            return functions, index\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Error loading existing data or index: {e}. Rebuilding...\")\n",
        "            # If loading fails, proceed to rebuild\n",
        "\n",
        "    # If data or index files do not exist, or loading failed, build them\n",
        "    print(f\"\\nğŸ—ï¸ No existing data or index found (or failed to load). Building a new one...\")\n",
        "\n",
        "    # Extract functions\n",
        "    functions = extract_functions(clone_path)\n",
        "    if not functions:\n",
        "        print(\"âŒ Error: No functions found. Cannot build index. Exiting.\")\n",
        "        return [], None # Return empty list and None for main to handle\n",
        "\n",
        "    # Save functions data\n",
        "    try:\n",
        "        with open(functions_path, 'w', encoding='utf-8') as f:\n",
        "            # json.dumpã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§éASCIIæ–‡å­—ã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã™ã‚‹ã®ã§ã€ensure_ascii=Falseã§æ—¥æœ¬èªãªã©ã‚’ãã®ã¾ã¾ä¿å­˜\n",
        "            json.dump(functions, f, indent=4, ensure_ascii=False)\n",
        "        print(f\"ğŸ’¾ Functions data saved at: {functions_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Warning: Could not save functions data to {functions_path}: {e}\")\n",
        "\n",
        "    # Embed codes\n",
        "    codes = [func[\"code\"] for func in functions]\n",
        "    embeddings = embed_codes(codes, model)\n",
        "\n",
        "    # Build FAISS index\n",
        "    index = build_faiss_index(embeddings)\n",
        "\n",
        "    # Save FAISS index\n",
        "    try:\n",
        "        faiss.write_index(index, index_path)\n",
        "        print(f\"ğŸ’¾ FAISS index saved at: {index_path}\")\n",
        "    except Exception as e:\n",
        "         print(f\"âš ï¸ Warning: Could not save FAISS index to {index_path}: {e}\")\n",
        "\n",
        "    return functions, index\n",
        "\n",
        "\n",
        "def search_functions(index, model, query, functions, top_k=5):\n",
        "    \"\"\"\n",
        "    Search for top-k most relevant functions given a natural language query.\n",
        "    \"\"\"\n",
        "    # Check if the model has a device attribute, if not, default to cpu\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    if hasattr(model, 'device'):\n",
        "         device = model.device\n",
        "\n",
        "    query_emb = model.encode([query], device=device)\n",
        "\n",
        "    D, I = index.search(np.array(query_emb).astype('float32'), top_k) # Embeddings might need float32\n",
        "\n",
        "    results = []\n",
        "    for idx in I[0]:\n",
        "         if 0 <= idx < len(functions): # Check if the index is within bounds\n",
        "              results.append(functions[idx])\n",
        "         else:\n",
        "              print(f\"âš ï¸ Warning: Invalid index {idx} returned from FAISS search. Skipping result.\")\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def pretty_print_results(results):\n",
        "    \"\"\"\n",
        "    Display search results in a clean format.\n",
        "    \"\"\"\n",
        "    print(\"\\nğŸ” Search Results:\")\n",
        "    if not results:\n",
        "        print(\"No relevant functions found.\")\n",
        "        return\n",
        "\n",
        "    for idx, res in enumerate(results, start=1):\n",
        "        print(f\"\\n=== Result {idx} ===\")\n",
        "        print(f\"ğŸ“„ File: {res['file_path']}\")\n",
        "        print(f\"ğŸ”§ Function: {res['function_name']}\")\n",
        "        print(f\"ğŸ§© Code Preview:\")\n",
        "        lines = res['code'].splitlines()\n",
        "        # Limit preview lines\n",
        "        preview_lines = 100\n",
        "        for line in lines[:preview_lines]:\n",
        "            print(line)\n",
        "        if len(lines) > preview_lines:\n",
        "            print(f\"... ({len(lines) - preview_lines} more lines truncated) ...\")\n",
        "\n",
        "\n",
        "def get_repo_name(repo_url):\n",
        "    \"\"\"\n",
        "    Extract the repository name from the GitHub URL.\n",
        "    \"\"\"\n",
        "    return repo_url.rstrip(\"/\").split(\"/\")[-1].replace(\".git\", \"\")\n",
        "\n",
        "# ===========================================\n",
        "# Main Execution\n",
        "# ===========================================\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # 1. Clone Repository\n",
        "        repo_name = get_repo_name(GITHUB_REPO_URL)\n",
        "        clone_path = os.path.join(SAVE_DIR, repo_name)\n",
        "        os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "        clone_repository(GITHUB_REPO_URL, clone_path)\n",
        "\n",
        "        # 2-6. Load or Build Data and Index\n",
        "        # This step handles extraction, embedding, building, and saving/loading\n",
        "        # of both functions data and the FAISS index.\n",
        "        print(\"\\nğŸ“¦ Loading embedding model...\")\n",
        "        model = SentenceTransformer(MODEL_NAME)\n",
        "\n",
        "        # Load or build functions data and FAISS index\n",
        "        functions, index = load_or_build_data_and_index(clone_path, model)\n",
        "\n",
        "        if not functions or index is None:\n",
        "             print(\"âŒ Could not load or build data/index. Exiting.\")\n",
        "             exit(3)\n",
        "\n",
        "        # 7. Search\n",
        "        while True: # Loop for multiple searches until empty query is entered\n",
        "            query = input(\"\\nğŸ’¬ Enter your search query (in English, or any language the embedding model handles well - press Enter only to quit): \")\n",
        "            if not query.strip():\n",
        "                print(\"ğŸ‘‹ Exiting search.\")\n",
        "                break\n",
        "\n",
        "            try:\n",
        "                results = search_functions(index, model, query, functions)\n",
        "                pretty_print_results(results)\n",
        "            except Exception as search_err:\n",
        "                print(f\"â— An error occurred during search: {search_err}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"â— Unexpected error occurred: {e}\")\n",
        "        exit(99)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================\n",
        "# â— ã”æ³¨æ„\n",
        "# ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€ŒGoogle Colabï¼ˆL4 GPUæ¨å¥¨ï¼‰ã€ã§ã®å®Ÿè¡Œã‚’æƒ³å®šã—ã¦ã„ã¾ã™ã€‚\n",
        "#\n",
        "# â‘  GitHubãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ã—ã€\n",
        "# â‘¡ .py, .ipynbãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰é–¢æ•°ã‚’æŠ½å‡ºã—ï¼ˆåˆå›ã®ã¿ï¼‰ã€\n",
        "# â‘¢ ã‚³ãƒ¼ãƒ‰ã‚’åŸ‹ã‚è¾¼ã¿ï¼ˆEmbeddingï¼‰ã—ï¼ˆåˆå›ã®ã¿ï¼‰ã€\n",
        "# â‘£ FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¦ä¿å­˜ã—ï¼ˆåˆå›ã®ã¿ï¼‰ã€\n",
        "# â‘¤ æ—¥æœ¬èªã‚¯ã‚¨ãƒªã‚’Qwen3-8B-FP8ã§è‹±è¨³ã—ã¦ã‹ã‚‰æ¤œç´¢ã—ã¾ã™ã€‚\n",
        "#\n",
        "# æ—¥æœ¬èªã§è³ªå•ã—ã¦ã‚‚è‹±èªã«ç¿»è¨³ã—ã¦é«˜ç²¾åº¦ã«æ¤œç´¢ã§ãã‚‹ä»•çµ„ã¿ã§ã™ï¼\n",
        "# åˆå›å®Ÿè¡Œæ™‚ã‚„ã‚³ãƒ¼ãƒ‰æ›´æ–°æ™‚ã«ã¯æŠ½å‡ºãƒ»åŸ‹ã‚è¾¼ã¿ãƒ»ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰ãŒè¡Œã‚ã‚Œã¾ã™ãŒã€\n",
        "# ãã‚Œä»¥é™ã¯ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ãŸã‚é«˜é€Ÿã«æ¤œç´¢ã§ãã¾ã™ï¼\n",
        "# ===========================================\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import json\n",
        "import lizard\n",
        "import faiss\n",
        "import torch\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# ===========================================\n",
        "# Settings\n",
        "# ===========================================\n",
        "GITHUB_REPO_URL = \"https://github.com/google-research/bert.git\"  # ğŸ”§ Change here\n",
        "SAVE_DIR = \"./cloned_repos\"\n",
        "MODEL_NAME = \"Shuu12121/CodeSearch-ModernBERT-Crow-Plus\"\n",
        "QWEN_MODEL = \"Qwen/Qwen3-8B-FP8\"\n",
        "MIN_FUNCTION_LENGTH = 3  # Minimum lines for function\n",
        "\n",
        "# ãƒ•ã‚¡ã‚¤ãƒ«åå®šç¾©\n",
        "FUNCTIONS_FILE = \"functions.json\"\n",
        "INDEX_FILE = \"faiss_index.bin\"\n",
        "\n",
        "# ===========================================\n",
        "# Helper Functions\n",
        "# ===========================================\n",
        "\n",
        "def clone_repository(repo_url, clone_dir):\n",
        "    if not os.path.exists(clone_dir):\n",
        "        subprocess.run([\"git\", \"clone\", repo_url, clone_dir], check=True)\n",
        "        print(f\"âœ… Repository cloned to {clone_dir}\")\n",
        "    else:\n",
        "        print(f\"â„¹ï¸ Repository already exists at {clone_dir}. Skipping clone.\")\n",
        "\n",
        "def extract_functions(repo_path):\n",
        "    functions = []\n",
        "    print(\"ğŸ“¥ Extracting functions...\")\n",
        "    for root, _, files in os.walk(repo_path):\n",
        "        files.sort()\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            # .gitãªã©ã®éš ã—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚„ä¸è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚¹ã‚­ãƒƒãƒ—\n",
        "            if \".git\" in file_path or \".ipynb_checkpoints\" in file_path:\n",
        "                 continue\n",
        "            try:\n",
        "                if file.endswith(\".py\"):\n",
        "                    analysis = lizard.analyze_file(file_path)\n",
        "                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "                        lines = f.readlines()\n",
        "                    for func in analysis.function_list:\n",
        "                        if hasattr(func, 'start_line') and hasattr(func, 'end_line'):\n",
        "                            start, end = max(func.start_line - 1, 0), func.end_line\n",
        "                            code = \"\".join(lines[start:end]) # joinã§æ–‡å­—åˆ—ã«ã™ã‚‹\n",
        "                            if len(code.strip().splitlines()) >= MIN_FUNCTION_LENGTH:\n",
        "                                functions.append({\n",
        "                                    \"file_path\": file_path,\n",
        "                                    \"function_name\": func.long_name,\n",
        "                                    \"code\": code\n",
        "                                })\n",
        "                elif file.endswith(\".ipynb\"):\n",
        "                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "                        data = json.load(f)\n",
        "                    for idx, cell in enumerate(data.get(\"cells\", [])):\n",
        "                        if cell.get(\"cell_type\") == \"code\":\n",
        "                            code = \"\".join(cell.get(\"source\", []))\n",
        "                            if len(code.strip().splitlines()) >= MIN_FUNCTION_LENGTH:\n",
        "                                functions.append({\n",
        "                                    \"file_path\": file_path,\n",
        "                                    \"function_name\": f\"cell_{idx}\",\n",
        "                                    \"code\": code\n",
        "                                })\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸ Warning: Could not process {file_path}: {e}\")\n",
        "    print(f\"âœ… Extracted {len(functions)} functions.\")\n",
        "    return functions\n",
        "\n",
        "def embed_codes(codes, model):\n",
        "    print(\"\\nğŸ“ˆ Encoding function codes...\")\n",
        "    return model.encode(codes, batch_size=32, show_progress_bar=True, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def build_faiss_index(embeddings):\n",
        "    print(\"\\nğŸ—ï¸ Building FAISS index...\")\n",
        "    dim = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatL2(dim)\n",
        "    index.add(embeddings)\n",
        "    return index\n",
        "\n",
        "def load_or_build_data_and_index(clone_path, model):\n",
        "    \"\"\"\n",
        "    æ—¢å­˜ã®functionsãƒ‡ãƒ¼ã‚¿ã¨FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€ç„¡ã‘ã‚Œã°æ–°ã—ãä½œæˆã™ã‚‹ã€‚\n",
        "    \"\"\"\n",
        "    functions_path = os.path.join(clone_path, FUNCTIONS_FILE)\n",
        "    index_path = os.path.join(clone_path, INDEX_FILE)\n",
        "\n",
        "    # ãƒ‡ãƒ¼ã‚¿ã¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä¸¡æ–¹ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯\n",
        "    if os.path.exists(functions_path) and os.path.exists(index_path):\n",
        "        print(f\"\\nğŸ”„ Loading existing data and index from {clone_path}...\")\n",
        "        try:\n",
        "            # functionsãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰\n",
        "            with open(functions_path, 'r', encoding='utf-8') as f:\n",
        "                functions = json.load(f)\n",
        "            # FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒ­ãƒ¼ãƒ‰\n",
        "            index = faiss.read_index(index_path)\n",
        "            print(\"âœ… Successfully loaded existing data and index.\")\n",
        "            return functions, index\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Error loading existing data or index: {e}. Rebuilding...\")\n",
        "            # ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ãŸå ´åˆã¯å†æ§‹ç¯‰ã¸é€²ã‚€\n",
        "\n",
        "    # ãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒå­˜åœ¨ã—ãªã„å ´åˆã€ã¾ãŸã¯ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ãŸå ´åˆ\n",
        "    print(f\"\\nğŸ—ï¸ No existing data or index found (or failed to load). Building a new one...\")\n",
        "\n",
        "    # functionsã‚’æŠ½å‡º\n",
        "    functions = extract_functions(clone_path)\n",
        "    if not functions:\n",
        "        print(\"âŒ Error: No functions found. Cannot build index. Exiting.\")\n",
        "        return [], None # ç©ºã®ãƒªã‚¹ãƒˆã¨Noneã‚’è¿”ã—ã¦ãƒ¡ã‚¤ãƒ³ã§ã‚¨ãƒ©ãƒ¼å‡¦ç†ã•ã›ã‚‹\n",
        "\n",
        "    # functionsãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜\n",
        "    try:\n",
        "        with open(functions_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(functions, f, indent=4)\n",
        "        print(f\"ğŸ’¾ Functions data saved at: {functions_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Warning: Could not save functions data to {functions_path}: {e}\")\n",
        "\n",
        "    # ã‚³ãƒ¼ãƒ‰ã‚’åŸ‹ã‚è¾¼ã¿\n",
        "    codes = [func[\"code\"] for func in functions]\n",
        "    embeddings = embed_codes(codes, model)\n",
        "\n",
        "    # FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰\n",
        "    index = build_faiss_index(embeddings)\n",
        "\n",
        "    # FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿å­˜\n",
        "    try:\n",
        "        faiss.write_index(index, index_path)\n",
        "        print(f\"ğŸ’¾ FAISS index saved at: {index_path}\")\n",
        "    except Exception as e:\n",
        "         print(f\"âš ï¸ Warning: Could not save FAISS index to {index_path}: {e}\")\n",
        "\n",
        "\n",
        "    return functions, index\n",
        "\n",
        "\n",
        "def search_functions(index, model, query, functions, top_k=5):\n",
        "    query_emb = model.encode([query], device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    D, I = index.search(np.array(query_emb), top_k)\n",
        "    results = []\n",
        "    for idx in I[0]:\n",
        "         if 0 <= idx < len(functions): # å¿µã®ãŸã‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ç¯„å›²ãƒã‚§ãƒƒã‚¯\n",
        "              results.append(functions[idx])\n",
        "         else:\n",
        "              print(f\"âš ï¸ Warning: Invalid index {idx} returned from FAISS search.\")\n",
        "    return results\n",
        "\n",
        "\n",
        "def pretty_print_results(results):\n",
        "    print(\"\\nğŸ” Search Results:\")\n",
        "    if not results:\n",
        "        print(\"No relevant functions found.\")\n",
        "        return\n",
        "    for idx, res in enumerate(results, start=1):\n",
        "        print(f\"\\n=== Result {idx} ===\")\n",
        "        print(f\"ğŸ“„ File: {res['file_path']}\")\n",
        "        print(f\"ğŸ”§ Function: {res['function_name']}\")\n",
        "        print(f\"ğŸ§© Code Preview:\")\n",
        "        lines = res['code'].splitlines()\n",
        "        # ã‚³ãƒ¼ãƒ‰ãŒé•·ã™ãã‚‹å ´åˆã¯ä¸€éƒ¨ã ã‘è¡¨ç¤º\n",
        "        preview_lines = 100\n",
        "        for line in lines[:preview_lines]:\n",
        "            print(line)\n",
        "        if len(lines) > preview_lines:\n",
        "            print(f\"... ({len(lines) - preview_lines} more lines truncated) ...\")\n",
        "\n",
        "def translate_to_english(qwen_model, qwen_tokenizer, japanese_text):\n",
        "    \"\"\"\n",
        "    Qwen3-8B-FP8ã‚’ä½¿ã£ã¦ã€æŠ€è¡“æ–‡æ›¸å‘ã‘ã«è‡ªç„¶ãªè‹±èªã¸ç¿»è¨³ã™ã‚‹ã€‚\n",
        "    \"\"\"\n",
        "    prompt_translate = f\"\"\"\n",
        "    ä»¥ä¸‹ã®æ—¥æœ¬èªã®å†…å®¹ã‚’ã€è‡ªç„¶ãªè‹±èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚\n",
        "    ãƒ»å°‚é–€ç”¨èªã‚„ã‚³ãƒ¼ãƒ‰ã®å¤‰æ•°åã¯ãã®ã¾ã¾ã«ã—ã¦ãã ã•ã„ã€‚\n",
        "    ãƒ»æ­£ç¢ºã‹ã¤è‡ªç„¶ãªè‹±èªã«ã—ã¦ãã ã•ã„ã€‚\n",
        "    ãƒ»ç¿»è¨³å¯¾è±¡:\n",
        "    ---\n",
        "    {japanese_text}\n",
        "    ---\n",
        "    è‹±è¨³:\n",
        "    \"\"\"\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt_translate.strip()}]\n",
        "\n",
        "    # æ¨è«–è¨­å®šã‚’æ˜ç¤ºçš„ã«æŒ‡å®š\n",
        "    generation_config = {\n",
        "        \"max_new_tokens\": 256,\n",
        "        \"do_sample\": True,\n",
        "        \"temperature\": 0.7,\n",
        "        \"top_p\": 0.8,\n",
        "        \"top_k\": 5,\n",
        "        \"min_p\": 0,\n",
        "        \"pad_token_id\": qwen_tokenizer.eos_token_id,\n",
        "        \"eos_token_id\": qwen_tokenizer.eos_token_id\n",
        "    }\n",
        "\n",
        "    text = qwen_tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True,\n",
        "        enable_thinking=False # ç°¡æ½”ã«ç¿»è¨³ã ã‘ã•ã›ã‚‹\n",
        "    )\n",
        "\n",
        "    inputs = qwen_tokenizer([text], return_tensors=\"pt\").to(qwen_model.device)\n",
        "\n",
        "    generated_ids = qwen_model.generate(\n",
        "        **inputs,\n",
        "        **generation_config # è¨­å®šã‚’æ¸¡ã™\n",
        "    )\n",
        "\n",
        "    # å…¥åŠ›éƒ¨åˆ†ã‚’é™¤å»ã—ã€ãƒªã‚¹ãƒˆã«å¤‰æ›\n",
        "    output_ids = generated_ids[0][len(inputs.input_ids[0]):].tolist()\n",
        "\n",
        "    # EOSãƒˆãƒ¼ã‚¯ãƒ³ã§åˆ‡æ–­\n",
        "    try:\n",
        "        # Qwenãƒ¢ãƒ‡ãƒ«ã¯è¤‡æ•°ã®EOSãƒˆãƒ¼ã‚¯ãƒ³ã‚’æŒã¤å ´åˆãŒã‚ã‚‹ã®ã§ã€ãƒªã‚¹ãƒˆã§æŒ‡å®šã™ã‚‹\n",
        "        # ã¾ãŸã¯tokenizer.eos_token_idãŒãƒªã‚¹ãƒˆã®å ´åˆã¯ãã‚Œã‚’ä½¿ã†\n",
        "        eos_ids = qwen_tokenizer.eos_token_id\n",
        "        if not isinstance(eos_ids, list):\n",
        "             eos_ids = [eos_ids]\n",
        "\n",
        "        min_eos_index = len(output_ids)\n",
        "        for eos_id in eos_ids:\n",
        "             try:\n",
        "                  idx = output_ids.index(eos_id)\n",
        "                  min_eos_index = min(min_eos_index, idx)\n",
        "             except ValueError:\n",
        "                  pass # EOSãƒˆãƒ¼ã‚¯ãƒ³ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ç¶šè¡Œ\n",
        "\n",
        "        output_ids = output_ids[:min_eos_index]\n",
        "\n",
        "    except Exception as e:\n",
        "        # ä¸‡ãŒä¸€ã®ä¾‹å¤–æ™‚ã‚‚ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚’è©¦ã¿ã‚‹\n",
        "        print(f\"âš ï¸ Warning during EOS token handling: {e}\")\n",
        "        pass\n",
        "\n",
        "\n",
        "    translated_text = qwen_tokenizer.decode(output_ids, skip_special_tokens=True).strip()\n",
        "\n",
        "    # Qwenã®å‡ºåŠ›ã®æœ€å¾Œã«ãŸã¾ã«ä¸è¦ãªæ–‡å­—ãŒã¤ãå ´åˆãŒã‚ã‚‹ã®ã§ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
        "    # ä¾‹: <|im_end|> ã‚„ãã‚Œã«é¡ã™ã‚‹ã‚‚ã®\n",
        "    # skip_special_tokens=True ã§å¤§æŠµã¯é™¤å»ã•ã‚Œã¾ã™ãŒã€å¿µã®ãŸã‚\n",
        "    # Qwenã®ç‰¹å®šã®å‡ºåŠ›å½¢å¼ã«åˆã‚ã›ã¦èª¿æ•´ãŒå¿…è¦ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“\n",
        "    # ã“ã“ã§ã¯ä¸€èˆ¬çš„ãªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã¯è¡Œã‚ãšã€decodeã®çµæœã‚’ä¿¡é ¼ã—ã¾ã™ã€‚\n",
        "    # å¿…è¦ã§ã‚ã‚Œã° translated_text = translated_text.split('<|im_end|>')[0].strip() ãªã©ã‚’è¿½åŠ \n",
        "\n",
        "    return translated_text\n",
        "\n",
        "\n",
        "def get_repo_name(repo_url):\n",
        "    return repo_url.rstrip(\"/\").split(\"/\")[-1].replace(\".git\", \"\")\n",
        "\n",
        "# ===========================================\n",
        "# Main Execution\n",
        "# ===========================================\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # 1. Clone repository\n",
        "        repo_name = get_repo_name(GITHUB_REPO_URL)\n",
        "        clone_path = os.path.join(SAVE_DIR, repo_name)\n",
        "        os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "        clone_repository(GITHUB_REPO_URL, clone_path)\n",
        "\n",
        "        # 2-6. Load or Build Data and Index\n",
        "        # ã“ã“ã§functionsã®æŠ½å‡ºã€åŸ‹ã‚è¾¼ã¿ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰ãƒ»ä¿å­˜ã€ã¾ãŸã¯èª­ã¿è¾¼ã¿ãŒè¡Œã‚ã‚Œã‚‹\n",
        "        print(\"\\nğŸ“¦ Loading embedding model...\")\n",
        "        model = SentenceTransformer(MODEL_NAME)\n",
        "\n",
        "        print(\"\\nğŸ“¦ Loading translation model (Qwen3-8B-FP8)...\")\n",
        "        qwen_tokenizer = AutoTokenizer.from_pretrained(QWEN_MODEL, trust_remote_code=True)\n",
        "        # device_map=\"auto\"ã‚’ä½¿ç”¨ã™ã‚‹ã¨ãƒ¢ãƒ‡ãƒ«ãŒè‡ªå‹•çš„ã«ãƒ‡ãƒã‚¤ã‚¹ã«é…ç½®ã•ã‚Œã‚‹\n",
        "        qwen_model = AutoModelForCausalLM.from_pretrained(QWEN_MODEL, torch_dtype=\"auto\", device_map=\"auto\", trust_remote_code=True)\n",
        "\n",
        "\n",
        "        # functionsãƒ‡ãƒ¼ã‚¿ã¨FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒ­ãƒ¼ãƒ‰ã¾ãŸã¯æ–°ã—ãæ§‹ç¯‰\n",
        "        functions, index = load_or_build_data_and_index(clone_path, model)\n",
        "\n",
        "        if not functions or index is None:\n",
        "             print(\"âŒ Could not load or build data/index. Exiting.\")\n",
        "             exit(3)\n",
        "\n",
        "        # 7. Search\n",
        "        while True: # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç©ºè¡Œã‚’å…¥åŠ›ã™ã‚‹ã¾ã§æ¤œç´¢ã‚’ç¹°ã‚Šè¿”ã™ãƒ«ãƒ¼ãƒ—\n",
        "            japanese_query = input(\"\\nğŸ’¬ æ—¥æœ¬èªã§æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ (çµ‚äº†ã™ã‚‹ã«ã¯Enterã‚­ãƒ¼ã®ã¿ã‚’æŠ¼ã™): \")\n",
        "            if not japanese_query.strip():\n",
        "                print(\"ğŸ‘‹ æ¤œç´¢ã‚’çµ‚äº†ã—ã¾ã™ã€‚\")\n",
        "                break\n",
        "\n",
        "            print(\"\\nğŸ”„ Translating query to English...\")\n",
        "            try:\n",
        "                english_query = translate_to_english(qwen_model, qwen_tokenizer, japanese_query)\n",
        "                print(f\"ğŸŒ English Query: {english_query}\")\n",
        "\n",
        "                results = search_functions(index, model, english_query, functions)\n",
        "                pretty_print_results(results)\n",
        "            except Exception as search_err:\n",
        "                print(f\"â— An error occurred during search or translation: {search_err}\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"â— Unexpected error occurred: {e}\")\n",
        "        exit(99)"
      ],
      "metadata": {
        "id": "0h2WY-i9gYbL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
